---
title: Redis为什么这么快
date:  2021-04-12 22:14:26
toc: true
tags: 
- redis
- 2021
- redis 进阶
categories:
- 知识体系
---

原文：https://haicoder.net/note/redis-interview/redis-interview-redis-fast.html

## Redis有多快

**[Redis](https://haicoder.net/redis/redis-tutorial.html)** 采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由 **[C 语言](https://haicoder.net/c/c-tutorial.html)** 编写，官方提供的数据是可以达到 100000+ 的 QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 **[Memcached](https://haicoder.net/memcached/memcached-tutorial.html)** 差！
<!-- more -->

Redis 具体 QPS 如下图所示：

![34_redis为什么快.png](https://wdj-1252419878.cos.ap-beijing.myqcloud.com/blog/2021-04-12-134853.jpg)

横轴是连接数，纵轴是 QPS。 此时，这张图反映了一个数量级！

## Redis为什么这么快

1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)；
2. 数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；
3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
4. 使用多路 I/O 复用模型，非阻塞 IO；
5. 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

### 多路I/O复用模型

多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

这里 “多路” 指的是多个网络连接，“复用” 指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响 Redis 性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

Redis 内部实现采用 epoll。

## 为什么Redis是单线程的

因为 Redis 是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

但是，我们使用单线程的方式是无法发挥多核 CPU 性能，不过我们可以通过在单机开多个 Redis 实例来完善！

这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的 Redis-Server 运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如 Redis 进行持久化的时候会以子进程的方式执行；例如我在测试服务器上查看 Redis 进程，然后找到该进程下的线程：

![35_redis为什么快.png](https://wdj-1252419878.cos.ap-beijing.myqcloud.com/blog/2021-04-12-134857.png)

我们可以看到，这里显示了三个 Redis—Server 的线程，ps 命令的 “-T” 参数表示显示线程（Show threads, possibly with SPID column.）“SID” 栏表示线程 ID，而 “CMD” 栏则显示了线程名称。

## Redis单线程对比多线程好处

### 上下文的切换

上下文其实不难理解，它就是 CPU 寄存器和程序计数器。主要的作用就是存放没有被分配到资源的线程，多线程操作的时候，不是每一个线程都能够直接获取到 CPU 资源的，我们之所以能够看到我们电脑上能够运行很多的程序，是应为多线程的执行和 CPU 不断对多线程的切换。但是总有线程获取到资源，也总有线程需要等待获取资源，这个时候，等待获取资源的线程就需要被挂起，也就是我们的寄存。这个时候我们的上下文就产生了，当我们的上下文再次被唤起，得到资源的时候，就是我们上下文的切换。

### 竞争资源

竞争资源相对来说比较好理解，CPU 对上下文的切换其实就是一种资源分批，但是在切换之前，到底切换到哪一个上下文，就是资源竞争的开始。在我 redis 中由于是单线程的，所以所有的操作都不会涉及到资源的竞争。

### 锁的消耗

对于多线程的情况来讲，不能回避的就是锁的问题。如果说多线程操作出现并发，有可能导致数据不一致，或者操作达不到预期的效果。这个时候我们就需要锁来解决这些问题。当我们的线程很多的时候，就需要不断的加锁，释放锁，该操作就会消耗掉我们很多的时间。

## 总结

Redis 为什么是单线程的是因为 Redis 的瓶颈不是 cpu 的运行速度，而往往是网络带宽和机器的内存大小。再说了，单线程切换开销小，容易实现既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。

如果万一 CPU 成为你的 Redis 瓶颈了，或者，你就是不想让服务器其他核闲置，那怎么办？那也很简单，你多起几个 Redis 进程就好了。Redis 是 keyvalue 数据库，又不是关系数据库，数据之间没有约束。只要客户端分清哪些 key 放在哪个 Redis 进程上就可以了。redis-cluster 可以帮你做的更好。

单线程可以处理高并发请求吗？当然可以了，Redis 都实现了。有一点概念需要澄清，并发并不是并行。（相关概念：并发性 I/O 流，意味着能够让一个计算单元来处理来自多个客户端的流请求。并行性，意味着服务器能够同时执行几个事情，具有多个计算单元）